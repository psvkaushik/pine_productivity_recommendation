{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Clustering         Model       MSE       MAE        R2\n",
      "0     KMeans       XGBoost  1.457232  0.879935  0.878101\n",
      "1     KMeans  RandomForest  1.485478  0.890422  0.875739\n",
      "2     KMeans           MLP  5.526616  1.712809  0.537695\n",
      "3        GMM       XGBoost  1.460071  0.880399  0.877864\n",
      "4        GMM  RandomForest  1.485998  0.890684  0.875695\n",
      "5        GMM           MLP  6.327234  1.905190  0.470722\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "# === Load train and test data ===\n",
    "train_df = pd.read_csv(\"../../data/tr_data.csv\")\n",
    "test_df = pd.read_csv(\"../../data/te_data.csv\")\n",
    "\n",
    "# === Drop unnecessary columns ===\n",
    "drop_cols = ['Unnamed: 0', 'TestId', 'date_initial', 'date_final', 'Feature', 'env', 'latitude', 'longitute']\n",
    "train_df = train_df.drop(columns=drop_cols, errors='ignore')\n",
    "test_df = test_df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# === Encode Species ===\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['species_encoded'] = label_encoder.fit_transform(train_df['Specie'])\n",
    "test_df['species_encoded'] = label_encoder.transform(test_df['Specie'])\n",
    "\n",
    "# === Drop non-numeric columns and missing values ===\n",
    "train_df = train_df.select_dtypes(include=[np.number]).dropna()\n",
    "test_df = test_df.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "# === Features and Targets ===\n",
    "X_train = train_df.drop(columns=['Productivity (y)'])\n",
    "y_train = train_df['Productivity (y)']\n",
    "\n",
    "X_test = test_df.drop(columns=['Productivity (y)'])\n",
    "y_test = test_df['Productivity (y)']\n",
    "\n",
    "# === Standardize features ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === Define clustering methods (ONLY KMeans and GMM) ===\n",
    "clustering_methods = {\n",
    "    'KMeans': KMeans(n_clusters=8, random_state=42),\n",
    "    'GMM': GaussianMixture(n_components=8, random_state=42)\n",
    "}\n",
    "\n",
    "# === Define regression models ===\n",
    "models = {\n",
    "    'XGBoost': xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'MLP': MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# === Store results ===\n",
    "results = []\n",
    "\n",
    "# === Loop through clustering methods and models ===\n",
    "for cluster_name, cluster_algo in clustering_methods.items():\n",
    "    # Fit clustering on training data\n",
    "    train_clusters = cluster_algo.fit_predict(X_train_scaled)\n",
    "    unique_clusters = np.unique(train_clusters)\n",
    "    \n",
    "    # For each model\n",
    "    for model_name, model_prototype in models.items():\n",
    "        cluster_models = {}\n",
    "\n",
    "        # Train a model for each cluster\n",
    "        for cluster_id in unique_clusters:\n",
    "            indices = np.where(train_clusters == cluster_id)[0]\n",
    "            X_cluster = X_train.iloc[indices]\n",
    "            y_cluster = y_train.iloc[indices]\n",
    "\n",
    "            model = model_prototype.__class__(**model_prototype.get_params())  # clone\n",
    "            model.fit(X_cluster, y_cluster)\n",
    "            cluster_models[cluster_id] = model\n",
    "        \n",
    "        # Predict on test set\n",
    "        test_predictions = []\n",
    "        for i in range(len(X_test)):\n",
    "            x_test_scaled = X_test_scaled[i].reshape(1, -1)\n",
    "            cluster_id = cluster_algo.predict(x_test_scaled)[0]\n",
    "\n",
    "            pred = cluster_models[cluster_id].predict(X_test.iloc[i:i+1])[0]\n",
    "            test_predictions.append(pred)\n",
    "\n",
    "        # Evaluate\n",
    "        mse = mean_squared_error(y_test, test_predictions)\n",
    "        mae = mean_absolute_error(y_test, test_predictions)\n",
    "        r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "        results.append({\n",
    "            'Clustering': cluster_name,\n",
    "            'Model': model_name,\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'R2': r2\n",
    "        })\n",
    "\n",
    "# === Display results ===\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
